{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c011300a",
   "metadata": {
    "id": "c011300a"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a34a55-1620-4286-8065-84212a6aff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-ignite\n",
    "!pip install torcheval\n",
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dird0uRs9vR5",
   "metadata": {
    "id": "dird0uRs9vR5"
   },
   "outputs": [],
   "source": [
    "COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "IVvWsDoq9w3y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 1059,
     "status": "ok",
     "timestamp": 1748290425504,
     "user": {
      "displayName": "IN FP",
      "userId": "08561517695641011702"
     },
     "user_tz": -120
    },
    "id": "IVvWsDoq9w3y",
    "outputId": "5a12b7f2-71cc-4235-c87c-76af65d0219f"
   },
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    import sys\n",
    "    import os\n",
    "    from google.colab import drive\n",
    "\n",
    "    # Mount Google Driveroo\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Add the path to the Python module\n",
    "    root_dir = '/content/drive/MyDrive/text_summarization'\n",
    "    sys.path.append(os.path.join(root_dir, 'src'))\n",
    "    sys.path.append(os.path.join(root_dir, 'src', 'utils'))\n",
    "else:\n",
    "    from pathlib import Path\n",
    "    root_dir = Path.cwd().parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c378699a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1932,
     "status": "ok",
     "timestamp": 1748290427445,
     "user": {
      "displayName": "IN FP",
      "userId": "08561517695641011702"
     },
     "user_tz": -120
    },
    "id": "c378699a",
    "outputId": "e626591d-073b-4109-bd8e-f7bdf8f08db0"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95a219a2",
   "metadata": {
    "id": "95a219a2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johannes/opt/anaconda3/envs/Language_Engineering_pip/lib/python3.11/site-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n"
     ]
    }
   ],
   "source": [
    "from train_model import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b8b3c11",
   "metadata": {
    "id": "3b8b3c11"
   },
   "outputs": [],
   "source": [
    "name = \"WikiHow\"\n",
    "legacy = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dddaa8e0",
   "metadata": {
    "id": "dddaa8e0"
   },
   "outputs": [],
   "source": [
    "\n",
    "raw_dir = os.path.join(root_dir, \"raw_data\", name)\n",
    "if legacy:\n",
    "    dataset_dir = os.path.join(root_dir, \"data\", name)\n",
    "    figures_dir = os.path.join(root_dir, \"figures\", name)\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "    os.makedirs(figures_dir, exist_ok=True)\n",
    "else:\n",
    "    dataset_dir = os.path.join(root_dir, \"data_packed\", name)\n",
    "    figures_dir = os.path.join(root_dir, \"figures_packed\", name)\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "    os.makedirs(figures_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b32c9d",
   "metadata": {
    "id": "17b32c9d"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7f42f2",
   "metadata": {
    "id": "db7f42f2"
   },
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "max_length = 100\n",
    "lr = 0.001\n",
    "weight_decay = 1e-6\n",
    "batch_size = 8\n",
    "num_workers = 2\n",
    "n_epochs = 3\n",
    "print_example_every = 5# 10_000\n",
    "log_every = 5# 1500\n",
    "load_checkpoint = False\n",
    "early_stopping_patience = 2\n",
    "hyp_tuning = False\n",
    "\n",
    "optimizer_hyperparams = {\n",
    "    'learning_rate': lr,\n",
    "    'weight_decay': weight_decay,\n",
    "    'n_epochs': n_epochs,\n",
    "    'batch_size': batch_size,\n",
    "    'num_workers': num_workers,\n",
    "    'early_stopping_patience': early_stopping_patience\n",
    "}\n",
    "\n",
    "model_hyperparams = {\n",
    "    'hidden_size': hidden_size,\n",
    "    'max_length': max_length\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bde23ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "executionInfo": {
     "elapsed": 977047,
     "status": "error",
     "timestamp": 1748294670175,
     "user": {
      "displayName": "IN FP",
      "userId": "08561517695641011702"
     },
     "user_tz": -120
    },
    "id": "7bde23ac",
    "outputId": "b5ef08c6-afff-40e7-a72c-49936dcaf55f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Loading tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johannes/Studium/Master/6. Semester/Language engineering/Project/text_summarization/src/train_model.py:202: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  X_train = torch.load(os.path.join(dataset_dir, \"x_train_list.pt\"), map_location=device)\n",
      "/Users/johannes/Studium/Master/6. Semester/Language engineering/Project/text_summarization/src/train_model.py:203: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  X_val = torch.load(os.path.join(dataset_dir, \"x_val_list.pt\"), map_location=device)\n",
      "/Users/johannes/Studium/Master/6. Semester/Language engineering/Project/text_summarization/src/train_model.py:204: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  y_train = torch.load(os.path.join(dataset_dir, \"y_train_list.pt\"), map_location=device)\n",
      "/Users/johannes/Studium/Master/6. Semester/Language engineering/Project/text_summarization/src/train_model.py:205: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  y_val = torch.load(os.path.join(dataset_dir, \"y_val_list.pt\"), map_location=device)\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]0.02s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "ERROR:tornado.general:SEND Error: Host unreachable\n",
      " 42%|████▏     | 5/12 [00:19<00:13,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating loss: 66.67%[Iter 5] Train loss: 6.2070, Val loss: 7.2723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 5/12 [00:20<00:28,  4.05s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (19) must match the size of tensor b (132) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_hyperparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_hyperparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtuning\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhyp_tuning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer_hyperparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer_hyperparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_every\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_every\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_examples_every\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_example_every\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mload_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlegacy\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlegacy\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Studium/Master/6. Semester/Language engineering/Project/text_summarization/src/train_model.py:347\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(root_dir, model_hyperparams, optimizer_hyperparams, log_every, print_examples_every, tuning, load_checkpoint, name, legacy)\u001b[39m\n\u001b[32m    344\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os.path.join(dataset_dir, \u001b[33m'\u001b[39m\u001b[33mfeature_tokenizer.pickle\u001b[39m\u001b[33m'\u001b[39m), \u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[32m    345\u001b[39m         feature_tokenizer = pickle.load(handle)\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_tokenizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_hyperparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_hyperparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer_hyperparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer_hyperparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_every\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_every\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_examples_every\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_examples_every\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtuning\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtuning\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mload_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlegacy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlegacy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    357\u001b[39m evaluate(root_dir=root_dir, name=name, device=device, feature_tokenizer=feature_tokenizer, \n\u001b[32m    358\u001b[39m          checkpoint_path=checkpoint_path, batch_size=optimizer_hyperparams[\u001b[33m'\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    359\u001b[39m          model_hyperparams=model_hyperparams, legacy=legacy)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Studium/Master/6. Semester/Language engineering/Project/text_summarization/src/train_model.py:256\u001b[39m, in \u001b[36mtraining_loop\u001b[39m\u001b[34m(root_dir, checkpoint_path, feature_tokenizer, device, name, model_hyperparams, optimizer_hyperparams, log_every, print_examples_every, tuning, load_checkpoint, legacy)\u001b[39m\n\u001b[32m    247\u001b[39m saved_metrics = {\n\u001b[32m    248\u001b[39m     \u001b[33m'\u001b[39m\u001b[33miteration\u001b[39m\u001b[33m'\u001b[39m: iteration_counter,\n\u001b[32m    249\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtrain_losses\u001b[39m\u001b[33m'\u001b[39m: plot_train_losses,\n\u001b[32m   (...)\u001b[39m\u001b[32m    252\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mval_metrics\u001b[39m\u001b[33m'\u001b[39m: plot_val_metrics\n\u001b[32m    253\u001b[39m }\n\u001b[32m    255\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m  \u001b[49m\u001b[43mindex2words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEOS_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigures_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m  \u001b[49m\u001b[43moptimizer_hyperparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaved_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_every\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_examples_every\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtuning\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlegacy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlegacy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Studium/Master/6. Semester/Language engineering/Project/text_summarization/src/train_model.py:147\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(train_dataloader, val_dataloader, encoder, decoder, criterion, index2words, EOS_token, checkpoint_path, figures_dir, optimizer_hyperparams, saved_metrics, log_every, print_examples_every, tuning, legacy)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, n_epochs + \u001b[32m1\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         early_stop = \u001b[43mtrain_epoch_packed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m            \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration_counter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_every\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_examples_every\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m            \u001b[49m\u001b[43mindex2words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEOS_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m            \u001b[49m\u001b[43mplot_train_losses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_val_losses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_val_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtuning\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_val_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m            \u001b[49m\u001b[43mno_improvement_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_patience\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m early_stop:\n\u001b[32m    158\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Studium/Master/6. Semester/Language engineering/Project/text_summarization/src/utils/training_utils.py:85\u001b[39m, in \u001b[36mtrain_epoch_packed\u001b[39m\u001b[34m(dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, val_dataloader, iteration_counter, log_every, print_examples_every, index2words, EOS_token, plot_train_losses, plot_val_losses, plot_val_metrics, tuning, checkpoint_path, best_val_loss_ref, no_improvement_count, early_stopping_patience)\u001b[39m\n\u001b[32m     82\u001b[39m     decoder.train()\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m iteration_counter % print_examples_every == \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tuning:\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     val_metrics = \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex2words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEOS_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlegacy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m metric_name \u001b[38;5;129;01min\u001b[39;00m plot_val_metrics.keys():\n\u001b[32m     87\u001b[39m         plot_val_metrics[metric_name].append(val_metrics[metric_name])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Studium/Master/6. Semester/Language engineering/Project/text_summarization/src/utils/training_utils.py:296\u001b[39m, in \u001b[36mevaluate_model\u001b[39m\u001b[34m(encoder, decoder, dataloader, index2word, EOS_token, legacy, test)\u001b[39m\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[32m    293\u001b[39m     input_tensor, input_lengths, target_tensor, target_lengths = data\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m     predicted_words = \u001b[43mmake_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex2word\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEOS_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlegacy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlegacy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_lengths\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_lengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    297\u001b[39m     target_words = decode_data(target_tensor[\u001b[32m0\u001b[39m], index2word, EOS_token)\n\u001b[32m    299\u001b[39m     predictions.append(predicted_words)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Studium/Master/6. Semester/Language engineering/Project/text_summarization/src/utils/training_utils.py:226\u001b[39m, in \u001b[36mmake_predictions\u001b[39m\u001b[34m(encoder, decoder, input_tensor, index2word, EOS_token, legacy, input_lengths)\u001b[39m\n\u001b[32m    224\u001b[39m     \u001b[38;5;66;03m# Shorten input_lengths as well\u001b[39;00m\n\u001b[32m    225\u001b[39m     input_lengths = input_lengths[\u001b[32m0\u001b[39m].unsqueeze(\u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m     encoder_outputs, encoder_hidden = \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_lengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    227\u001b[39m     decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, encoder_mask, target_tensor)\n\u001b[32m    230\u001b[39m \u001b[38;5;66;03m# Get the predicted words\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/Language_Engineering_pip/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/Language_Engineering_pip/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Studium/Master/6. Semester/Language engineering/Project/text_summarization/src/utils/models.py:173\u001b[39m, in \u001b[36mEncoderRNN_packed.forward\u001b[39m\u001b[34m(self, input, lengths, encoder_mask)\u001b[39m\n\u001b[32m    170\u001b[39m output, _ = pad_packed_sequence(output_packed, batch_first=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    172\u001b[39m \u001b[38;5;66;03m# Combine the two directions by mean (use the mask to be safe. I dont think we really need it because pad_packed_sequence should pad with 0s but better be save than sorry here...)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m masked_output = \u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_mask\u001b[49m\u001b[43m.\u001b[49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (B, S, 2H)\u001b[39;00m\n\u001b[32m    174\u001b[39m mean_hidden = masked_output.sum(dim=\u001b[32m1\u001b[39m) / lengths.unsqueeze(\u001b[32m1\u001b[39m).to(output.dtype)  \u001b[38;5;66;03m# (B, 2H)\u001b[39;00m\n\u001b[32m    175\u001b[39m hidden = torch.tanh(\u001b[38;5;28mself\u001b[39m.output_projection(mean_hidden))  \u001b[38;5;66;03m# (B, H)\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (19) must match the size of tensor b (132) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "main(root_dir=root_dir,\n",
    "    model_hyperparams=model_hyperparams,\n",
    "    tuning=hyp_tuning,\n",
    "    optimizer_hyperparams=optimizer_hyperparams,\n",
    "    log_every=log_every,\n",
    "    print_examples_every=print_example_every,\n",
    "    load_checkpoint=load_checkpoint,\n",
    "    name=name,\n",
    "    legacy = legacy\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8cd4e20-88e6-41dd-89b6-dd2138ad0f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# !tensorboard --logdir='tensorboard_logs'"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Language_Engineering_pip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
