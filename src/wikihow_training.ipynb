{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c011300a",
   "metadata": {
    "id": "c011300a"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55a34a55-1620-4286-8065-84212a6aff18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-ignite in /opt/conda/lib/python3.10/site-packages (0.5.2)\n",
      "Requirement already satisfied: torch<3,>=1.3 in /opt/conda/lib/python3.10/site-packages (from pytorch-ignite) (2.1.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from pytorch-ignite) (23.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<3,>=1.3->pytorch-ignite) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch<3,>=1.3->pytorch-ignite) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<3,>=1.3->pytorch-ignite) (1.3.0)\n",
      "Requirement already satisfied: torcheval in /opt/conda/lib/python3.10/site-packages (0.0.7)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torcheval) (4.9.0)\n",
      "Requirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (4.3.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (1.13.1)\n",
      "Requirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optuna) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (23.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/conda/lib/python3.10/site-packages (from optuna) (2.0.25)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from optuna) (4.66.1)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.9.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.4.2->optuna) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-ignite\n",
    "!pip install torcheval\n",
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dird0uRs9vR5",
   "metadata": {
    "id": "dird0uRs9vR5"
   },
   "outputs": [],
   "source": [
    "COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "IVvWsDoq9w3y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 1059,
     "status": "ok",
     "timestamp": 1748290425504,
     "user": {
      "displayName": "IN FP",
      "userId": "08561517695641011702"
     },
     "user_tz": -120
    },
    "id": "IVvWsDoq9w3y",
    "outputId": "5a12b7f2-71cc-4235-c87c-76af65d0219f"
   },
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    import sys\n",
    "    import os\n",
    "    from google.colab import drive\n",
    "\n",
    "    # Mount Google Driveroo\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Add the path to the Python module\n",
    "    root_dir = '/content/drive/MyDrive/text_summarization'\n",
    "    sys.path.append(os.path.join(root_dir, 'src'))\n",
    "    sys.path.append(os.path.join(root_dir, 'src', 'utils'))\n",
    "else:\n",
    "    from pathlib import Path\n",
    "    root_dir = Path.cwd().parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c378699a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1932,
     "status": "ok",
     "timestamp": 1748290427445,
     "user": {
      "displayName": "IN FP",
      "userId": "08561517695641011702"
     },
     "user_tz": -120
    },
    "id": "c378699a",
    "outputId": "e626591d-073b-4109-bd8e-f7bdf8f08db0"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95a219a2",
   "metadata": {
    "id": "95a219a2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "2025-06-02 12:06:47.559199: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-02 12:06:47.589515: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-02 12:06:47.589531: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-02 12:06:47.590445: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-02 12:06:47.596287: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from train_model import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8b3c11",
   "metadata": {
    "id": "3b8b3c11"
   },
   "outputs": [],
   "source": [
    "name = \"WikiHow\"\n",
    "legacy = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddaa8e0",
   "metadata": {
    "id": "dddaa8e0"
   },
   "outputs": [],
   "source": [
    "\n",
    "raw_dir = os.path.join(root_dir, \"raw_data\", name)\n",
    "if legacy:\n",
    "    dataset_dir = os.path.join(root_dir, \"data\", name)\n",
    "    figures_dir = os.path.join(root_dir, \"figures\", name)\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "    os.makedirs(figures_dir, exist_ok=True)\n",
    "else:\n",
    "    dataset_dir = os.path.join(root_dir, \"data_packed\", name)\n",
    "    figures_dir = os.path.join(root_dir, \"figures_packed\", name)\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "    os.makedirs(figures_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b32c9d",
   "metadata": {
    "id": "17b32c9d"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7f42f2",
   "metadata": {
    "id": "db7f42f2"
   },
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "max_length = 100\n",
    "lr = 0.001\n",
    "weight_decay = 1e-6\n",
    "batch_size = 8\n",
    "num_workers = 2\n",
    "n_epochs = 1\n",
    "print_example_every = 10_000\n",
    "log_every = 1500\n",
    "load_checkpoint = True\n",
    "early_stopping_patience = 5\n",
    "hyp_tuning = False\n",
    "\n",
    "optimizer_hyperparams = {\n",
    "    'learning_rate': lr,\n",
    "    'weight_decay': weight_decay,\n",
    "    'n_epochs': n_epochs,\n",
    "    'batch_size': batch_size,\n",
    "    'num_workers': num_workers,\n",
    "    'early_stopping_patience': early_stopping_patience\n",
    "}\n",
    "\n",
    "model_hyperparams = {\n",
    "    'hidden_size': hidden_size,\n",
    "    'max_length': max_length\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bde23ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "executionInfo": {
     "elapsed": 977047,
     "status": "error",
     "timestamp": 1748294670175,
     "user": {
      "displayName": "IN FP",
      "userId": "08561517695641011702"
     },
     "user_tz": -120
    },
    "id": "7bde23ac",
    "outputId": "b5ef08c6-afff-40e7-a72c-49936dcaf55f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Loading tokenizer\n",
      "Loading checkpoint...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 42000/58817 [09:10<1:42:39,  2.73it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating loss: 99.98%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 42001/58817 [28:42<1642:18:11, 351.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating loss: 99.99%[Iter 42000] Train loss: 0.1619, Val loss: 4.4770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 43500/58817 [37:51<1:33:28,  2.73it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating loss: 99.98%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 43501/58817 [57:21<1494:54:47, 351.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating loss: 99.99%[Iter 43500] Train loss: 0.3103, Val loss: 4.3831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 45000/58817 [1:06:30<1:24:20,  2.73it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating loss: 99.98%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 45001/58817 [1:26:00<1348:30:32, 351.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating loss: 99.99%[Iter 45000] Train loss: 0.4450, Val loss: 4.3339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 46500/58817 [1:35:10<1:15:09,  2.73it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating loss: 99.98%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 46501/58817 [1:54:40<1202:27:44, 351.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating loss: 99.99%[Iter 46500] Train loss: 0.5698, Val loss: 4.2990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 48000/58817 [2:03:50<1:06:04,  2.73it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating loss: 99.98%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 48001/58817 [2:23:22<1057:10:13, 351.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating loss: 99.99%Early stopping triggered at iteration 48000\n",
      "[Iter 48000] Train loss: 0.6861, Val loss: 4.2632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 49500/58817 [2:32:32<56:57,  2.73it/s]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating loss: 99.98%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 49501/58817 [2:52:05<911:00:46, 352.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating loss: 99.99%Early stopping triggered at iteration 49500\n",
      "[Iter 49500] Train loss: 0.7942, Val loss: 4.2617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 50000/58817 [2:55:08<53:53,  2.73it/s]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: 99.99%-----------------------------------\n",
      "BLEU score: 0.1098\n",
      "Rouge-L-F score: 1.0000\n",
      "Rouge-1-F score: 1.0000\n",
      "Rouge-2-F score: 0.6000\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "BLEU score: 0.1098\n",
      "Rouge-L-F score: 1.0000\n",
      "Rouge-1-F score: 1.0000\n",
      "Rouge-2-F score: 0.6000\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "BLEU score: 0.1098\n",
      "Rouge-L-F score: 1.0000\n",
      "Rouge-1-F score: 1.0000\n",
      "Rouge-2-F score: 0.6000\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "BLEU score: 0.1098\n",
      "Rouge-L-F score: 1.0000\n",
      "Rouge-1-F score: 1.0000\n",
      "Rouge-2-F score: 0.6000\n",
      "-----------------------------------\n",
      "Input: SOS your kidneys are primarily responsible for filtering out excessive levels of potassium from the bloodstream if you have acute or chronic renal failure or adrenal gland dysfunction then monitor your potassium levels to make sure they stay within a safe range cancer treatments which destroy cells or cell UNK can also lead to increased levels of potassium EOS\n",
      "Target: SOS know your body EOS\n",
      "Predicted: SOS avoid smoking EOS\n",
      "-----------------------------------\n",
      "Input: SOS garlic may help more with lowering ldl cholesterol than increasing hdl cholesterol but it does decrease the cholesterol ratio include a garlic supplement to see if this helps to improve your cholesterol ratio take 900 mg of garlic powder every day make sure that you check with your doctor first because garlic can interact with some medications such as blood thinners garlic supplements have also been shown to lower triglyceride levels EOS\n",
      "Target: SOS try a garlic supplement EOS\n",
      "Predicted: SOS use your garlic EOS\n",
      "-----------------------------------\n",
      "Input: SOS this is stuffing EOS\n",
      "Target: SOS mix the wild leeks with the red pepper powder green onions garlic ginger and pickled baby shrimp along with its juice seasoned salt and sugar EOS\n",
      "Predicted: SOS use the red cream EOS\n",
      "-----------------------------------\n",
      "Input: SOS rocks and other big scenery are often the best place to try to find glitches sometimes the game developers get lazy and dont set up barriers there if you go to a rock to try to glitch into it or out of a map try to go to the most obscure edge of it the most protruding edge that is obviously different from the others could be the key to getting inside it if you are new to glitching try not to go for the hard glitches like going out of map or under map try to get on roofs for a while and then move on to advanced glitches EOS\n",
      "Target: SOS check out the big things EOS\n",
      "Predicted: SOS play games EOS\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 50001/58817 [3:31:19<1595:31:29, 651.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: SOS its not good for brushes to be wet for extended periods of time after you finish rinsing out the soap wrap the bristles of the brush in a paper towel or a clean rag then gently squeeze to release waterlay your brushes out to dry horizontally storing them vertically on their bristles can bend the bristles out of shape EOS\n",
      "Target: SOS dry the brush EOS\n",
      "Predicted: SOS rinse the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 51000/58817 [3:37:26<47:52,  2.72it/s]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating loss: 99.98%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 51001/58817 [3:56:58<764:02:38, 351.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating loss: 99.99%Early stopping triggered at iteration 51000\n",
      "[Iter 51000] Train loss: 0.8953, Val loss: 4.2297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 52500/58817 [4:06:09<38:42,  2.72it/s]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating loss: 99.99%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 52501/58817 [4:25:42<617:46:33, 352.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 52500] Train loss: 0.9906, Val loss: 4.2049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 54000/58817 [4:34:53<29:23,  2.73it/s]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating loss: 99.99%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 54001/58817 [4:54:25<470:53:50, 352.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 54000] Train loss: 1.0802, Val loss: 4.1870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 55500/58817 [5:03:37<20:19,  2.72it/s]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating loss: 99.99%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 55501/58817 [5:23:10<324:26:08, 352.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 55500] Train loss: 1.1645, Val loss: 4.1726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 57000/58817 [5:32:21<11:08,  2.72it/s]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating loss: 99.98%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 57001/58817 [5:51:54<177:40:52, 352.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating loss: 99.99%[Iter 57000] Train loss: 1.2440, Val loss: 4.1729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 58500/58817 [6:01:06<01:56,  2.72it/s]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating loss: 99.99%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 58501/58817 [6:20:38<30:54:29, 352.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 58500] Train loss: 1.3188, Val loss: 4.1571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58817/58817 [6:22:35<00:00,  2.56it/s]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating loss: 99.99%Test loss: 4.1601\n",
      "Evaluating model: 99.99%-----------------------------------\n",
      "BLEU score: 0.0982\n",
      "Rouge-L-F score: 1.0000\n",
      "Rouge-1-F score: 1.0000\n",
      "Rouge-2-F score: 0.5000\n",
      "-----------------------------------\n",
      "Input: SOS if you controller disconnects every time it rumbles or shakes your battery pack may be loose while the easiest way to fix this is to buy a new one you can also use tape the secure it tightly to the back of your controller taping up your battery pack is usually a temporary solution and makes it difficult to replace dead batteries EOS\n",
      "Target: SOS secure your battery pack if it is loose or jiggling EOS\n",
      "Predicted: SOS install the battery EOS\n",
      "-----------------------------------\n",
      "Input: SOS dont criticize your spouses efforts around the house especially while theyre still learning they may never do chores exactly to your liking especially if you have very high standards for cleanliness instead focus on appreciating their helpif you really want a particular task done a certain way its probably best to do it yourself EOS\n",
      "Target: SOS keep your expectations realistic EOS\n",
      "Predicted: SOS be honest EOS\n",
      "-----------------------------------\n",
      "Input: SOS the new ringtone will be show up on the itunes interface ready to be synced to your iphone EOS\n",
      "Target: SOS as soon as you change the files extension itll appear as an itunes ringtone that you can import into itunes straight away with just a double click EOS\n",
      "Predicted: SOS click on the settings menu EOS\n",
      "-----------------------------------\n",
      "Input: SOS ignite the tinder at the base of the wood blow gently on the flame from the burning tinder until the larger sticks catch keep the flames stoked by adding bits of kindling smaller twigs leaves and other dry brush periodically as the fire grows hotter you can begin piling on more UNK your fire somewhere with adequate coverage protected from wind and precipitation it may help to dig a shallow pit in which to place the UNK putting wet wood or fresh foliage into the fire these things dont burn easily and will often produce thick choking smoke EOS\n",
      "Target: SOS light the fire EOS\n",
      "Predicted: SOS remove the remaining pieces EOS\n",
      "-----------------------------------\n",
      "Input: SOS there should be an arch supporta contoured piece to fit your childs foot the slope of the arch should start at the base of your childs big toe EOS\n",
      "Target: SOS look at the inside arch of the shoe EOS\n",
      "Predicted: SOS make a small tank EOS\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "main(root_dir=root_dir,\n",
    "    model_hyperparams=model_hyperparams,\n",
    "    tuning=hyp_tuning,\n",
    "    optimizer_hyperparams=optimizer_hyperparams,\n",
    "    log_every=log_every,\n",
    "    print_examples_every=print_example_every,\n",
    "    load_checkpoint=load_checkpoint,\n",
    "    name=name,\n",
    "    legacy = legacy\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8cd4e20-88e6-41dd-89b6-dd2138ad0f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# !tensorboard --logdir='tensorboard_logs'"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
