{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c011300a",
   "metadata": {
    "id": "c011300a"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dird0uRs9vR5",
   "metadata": {
    "id": "dird0uRs9vR5"
   },
   "outputs": [],
   "source": [
    "COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IVvWsDoq9w3y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 1059,
     "status": "ok",
     "timestamp": 1748290425504,
     "user": {
      "displayName": "IN FP",
      "userId": "08561517695641011702"
     },
     "user_tz": -120
    },
    "id": "IVvWsDoq9w3y",
    "outputId": "5a12b7f2-71cc-4235-c87c-76af65d0219f"
   },
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    import sys\n",
    "    import os\n",
    "    from google.colab import drive\n",
    "\n",
    "    # Mount Google Driveroo\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Add the path to the Python module\n",
    "    root_dir = '/content/drive/MyDrive/text_summarization'\n",
    "    sys.path.append(os.path.join(root_dir, 'src'))\n",
    "    sys.path.append(os.path.join(root_dir, 'src', 'utils'))\n",
    "else:\n",
    "    from pathlib import Path\n",
    "    root_dir = Path.cwd().parent\n",
    "root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c378699a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1932,
     "status": "ok",
     "timestamp": 1748290427445,
     "user": {
      "displayName": "IN FP",
      "userId": "08561517695641011702"
     },
     "user_tz": -120
    },
    "id": "c378699a",
    "outputId": "e626591d-073b-4109-bd8e-f7bdf8f08db0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a219a2",
   "metadata": {
    "id": "95a219a2"
   },
   "outputs": [],
   "source": [
    "from utils.preprocessing import preprocessing_pipeline, get_data_distribution\n",
    "from utils.processing import processing_pipeline\n",
    "from train_model import main, tuning\n",
    "from utils.inference import main\n",
    "from optuna.visualization import (plot_optimization_history,\n",
    "                                  plot_param_importances, plot_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66186581",
   "metadata": {
    "id": "66186581"
   },
   "outputs": [],
   "source": [
    "PROCESSING = True\n",
    "PREPROCESSING = True\n",
    "HYP_TUNING = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8b3c11",
   "metadata": {
    "id": "3b8b3c11"
   },
   "outputs": [],
   "source": [
    "name = \"WikiHow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddaa8e0",
   "metadata": {
    "id": "dddaa8e0"
   },
   "outputs": [],
   "source": [
    "raw_dir = os.path.join(root_dir, \"raw_data\", name)\n",
    "dataset_dir = os.path.join(root_dir, \"data\", name)\n",
    "figures_dir = os.path.join(root_dir, \"figures\", name)\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "os.makedirs(figures_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1ffb00",
   "metadata": {
    "id": "4d1ffb00"
   },
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a38208",
   "metadata": {
    "id": "c3a38208"
   },
   "outputs": [],
   "source": [
    "dataset_df = pd.read_csv(os.path.join(raw_dir, \"wikihowSep.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db627eaf",
   "metadata": {
    "id": "db627eaf"
   },
   "outputs": [],
   "source": [
    "csv_name = \"wikihow_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31e12c1",
   "metadata": {
    "id": "e31e12c1"
   },
   "source": [
    "## Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549c6283",
   "metadata": {
    "id": "549c6283"
   },
   "outputs": [],
   "source": [
    "if PREPROCESSING:\n",
    "    preprocessing_pipeline(dataset_df, stopwords, dataset_dir, csv_name, subset_size = 0.5, start_token = \"SOS \", end_token = \" EOS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f09257",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5335,
     "status": "ok",
     "timestamp": 1748290468515,
     "user": {
      "displayName": "IN FP",
      "userId": "08561517695641011702"
     },
     "user_tz": -120
    },
    "id": "31f09257",
    "outputId": "eda4d71c-8c70-4912-9e2f-24a19e659e43"
   },
   "outputs": [],
   "source": [
    "dataset_df = pd.read_csv(os.path.join(root_dir, \"data\", name, f'{csv_name}.csv'))\n",
    "dataset_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kSWsLCeWKqcg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1748290468527,
     "user": {
      "displayName": "IN FP",
      "userId": "08561517695641011702"
     },
     "user_tz": -120
    },
    "id": "kSWsLCeWKqcg",
    "outputId": "c2daf0b4-dd08-4f23-b148-f3109c9e9c67"
   },
   "outputs": [],
   "source": [
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15abfd00",
   "metadata": {
    "id": "15abfd00"
   },
   "source": [
    "## Get distribution of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8f0f01",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 602
    },
    "executionInfo": {
     "elapsed": 8582,
     "status": "ok",
     "timestamp": 1748290477113,
     "user": {
      "displayName": "IN FP",
      "userId": "08561517695641011702"
     },
     "user_tz": -120
    },
    "id": "cb8f0f01",
    "outputId": "476bc6e5-ac3f-46e8-920b-f1eab97b9466"
   },
   "outputs": [],
   "source": [
    "get_data_distribution(dataset_df, figures_dir, \"wikihow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596a84bd",
   "metadata": {
    "id": "596a84bd"
   },
   "source": [
    "## Process the datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a564bcf3",
   "metadata": {
    "id": "a564bcf3"
   },
   "outputs": [],
   "source": [
    "load_tokenizer = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d4ef07-990c-4b19-906b-ca0c75c4e833",
   "metadata": {
    "id": "90a837db"
   },
   "outputs": [],
   "source": [
    "if PROCESSING:\n",
    "    processing_pipeline(dataset_dir, csv_name, load_tokenizer = load_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4024c6ff-96de-466d-83e1-f7b14d280c67",
   "metadata": {},
   "source": [
    "### Test the processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f75936-b37b-4668-8f04-5869ec579b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_decoding = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc2362a-b656-413e-b6a7-663d3bc9311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_decoding:\n",
    "    import torch\n",
    "    import pickle\n",
    "    import random\n",
    "    \n",
    "    def decode_data(text_ids, index2word, EOS_token):\n",
    "        \"\"\"\n",
    "        Converts the text ids to words using the index2word mapping.\n",
    "        \"\"\"\n",
    "        if text_ids.dim() > 1:\n",
    "            text_ids = text_ids.view(-1)  # Flatten to 1D\n",
    "    \n",
    "        decoded_words = []\n",
    "        for idx in text_ids:\n",
    "            # Ensure idx is a scalar\n",
    "            if isinstance(idx, torch.Tensor):\n",
    "                idx = idx.item()\n",
    "            if idx == EOS_token:\n",
    "                decoded_words.append('EOS')\n",
    "                break\n",
    "            decoded_words.append(index2word.get(idx, 'UNK'))\n",
    "    \n",
    "        return \" \".join(decoded_words)\n",
    "    \n",
    "    X_train = torch.load(os.path.join(dataset_dir, \"x_train.pt\"))\n",
    "    y_train = torch.load(os.path.join(dataset_dir, \"y_train.pt\"))\n",
    "    \n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        torch.utils.data.TensorDataset(X_train, y_train),\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    with open(os.path.join(dataset_dir, 'feature_tokenizer.pickle'), 'rb') as handle:\n",
    "            feature_tokenizer = pickle.load(handle)\n",
    "    EOS_token = feature_tokenizer.word2index.get(\"EOS\", 2)\n",
    "    \n",
    "    nb_decoding_test = 10\n",
    "    count_test = 0\n",
    "    random_list = random.sample(range(len(train_dataloader)), nb_decoding_test)\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        if i in random_list:\n",
    "            input_tensor, target_tensor = data\n",
    "            print('Input: {}'.format(decode_data(input_tensor[0], feature_tokenizer.index2word, EOS_token)))\n",
    "            print('Target: {}'.format(decode_data(target_tensor[0], feature_tokenizer.index2word, EOS_token)))\n",
    "            print('-----------------------------------')\n",
    "            count_test += 1\n",
    "        if count_test == nb_decoding_test:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b32c9d",
   "metadata": {
    "id": "17b32c9d"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7f42f2",
   "metadata": {
    "id": "db7f42f2"
   },
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "max_length = 100\n",
    "lr = 0.001\n",
    "weight_decay = 1e-4\n",
    "batch_size = 128\n",
    "num_workers = 2\n",
    "n_epochs = 100\n",
    "print_example_every = 10\n",
    "load_checkpoint = False\n",
    "early_stopping_patience = 5\n",
    "\n",
    "optimizer_hyperparams = {\n",
    "    'learning_rate': lr,\n",
    "    'weight_decay': weight_decay,\n",
    "    'n_epochs': n_epochs,\n",
    "    'batch_size': batch_size,\n",
    "    'num_workers': num_workers,\n",
    "    'early_stopping_patience': early_stopping_patience\n",
    "}\n",
    "\n",
    "model_hyperparams = {\n",
    "    'hidden_size': hidden_size,\n",
    "    'max_length': max_length\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bde23ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "executionInfo": {
     "elapsed": 977047,
     "status": "error",
     "timestamp": 1748294670175,
     "user": {
      "displayName": "IN FP",
      "userId": "08561517695641011702"
     },
     "user_tz": -120
    },
    "id": "7bde23ac",
    "outputId": "b5ef08c6-afff-40e7-a72c-49936dcaf55f"
   },
   "outputs": [],
   "source": [
    "main(root_dir = root_dir,\n",
    "    model_hyperparams=model_hyperparams,\n",
    "    tuning = False, \n",
    "    optimizer_hyperparams=optimizer_hyperparams,\n",
    "    print_examples_every=print_example_every,\n",
    "    load_checkpoint=load_checkpoint,\n",
    "    name=name\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0617b5c-6156-4ee1-a78a-cb59fbc2f243",
   "metadata": {},
   "source": [
    "### Making inference with the model (on a CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025c633a-f75d-4142-bae2-933a08c54671",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = 'best_checkpoint.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d585a80d-a92f-435a-b6e3-015eea7b9f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    input_tensor = input(\"Enter the text to summarize (or type 'exit' to quit): \")\n",
    "    if input_tensor.lower() == 'exit':\n",
    "        break\n",
    "    # Don't forget to water your plants, they need it to survive.\n",
    "    main(root_dir, name, checkpoint_name, hidden_size, max_length, input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c090fe-4407-4a3c-b6f2-f47d6836f31a",
   "metadata": {},
   "source": [
    "### Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09efad8-2f38-4175-9b97-069ce8f46420",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c77807-8a8a-4171-b806-cd5a9ea9f052",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HYP_TUNING:\n",
    "    study = tuning(root_dir, num_trials, name)\n",
    "    # Save the study results\n",
    "    study_dir = os.path.join(root_dir, 'parameters_tuning', name, 'study_results')\n",
    "    os.makedirs(study_dir, exist_ok=True)\n",
    "    \n",
    "    # Save the optimization history\n",
    "    plot_optimization_history(study)\n",
    "    \n",
    "    # Save the parameter importances\n",
    "    plot_param_importances(study)\n",
    "    \n",
    "    # Save the slice plot\n",
    "    plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496f806a-4f1a-4702-81f3-1ad73a08bfd4",
   "metadata": {},
   "source": [
    "### Check training information with tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d951d2-ca13-47a6-b99b-27730cefe1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# !tensorboard --logdir='tensorboard_logs'"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
