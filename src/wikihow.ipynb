{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c011300a",
   "metadata": {
    "id": "c011300a"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5214fc38-6d0f-4b9c-8b1a-16a81c9ccfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-ignite in /opt/conda/lib/python3.10/site-packages (0.5.2)\n",
      "Requirement already satisfied: torch<3,>=1.3 in /opt/conda/lib/python3.10/site-packages (from pytorch-ignite) (2.1.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from pytorch-ignite) (23.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<3,>=1.3->pytorch-ignite) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch<3,>=1.3->pytorch-ignite) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<3,>=1.3->pytorch-ignite) (1.3.0)\n",
      "Requirement already satisfied: torcheval in /opt/conda/lib/python3.10/site-packages (0.0.7)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torcheval) (4.9.0)\n",
      "Requirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (4.3.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (1.13.1)\n",
      "Requirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optuna) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (23.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/conda/lib/python3.10/site-packages (from optuna) (2.0.25)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from optuna) (4.66.1)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.9.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.4.2->optuna) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.4)\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (6.1.2)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /opt/conda/lib/python3.10/site-packages (from plotly) (1.41.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from plotly) (23.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-ignite\n",
    "!pip install torcheval\n",
    "!pip install optuna\n",
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dird0uRs9vR5",
   "metadata": {
    "id": "dird0uRs9vR5"
   },
   "outputs": [],
   "source": [
    "COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "IVvWsDoq9w3y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 1059,
     "status": "ok",
     "timestamp": 1748290425504,
     "user": {
      "displayName": "IN FP",
      "userId": "08561517695641011702"
     },
     "user_tz": -120
    },
    "id": "IVvWsDoq9w3y",
    "outputId": "5a12b7f2-71cc-4235-c87c-76af65d0219f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/jovyan/text_summarization')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if COLAB:\n",
    "    import sys\n",
    "    import os\n",
    "    from google.colab import drive\n",
    "\n",
    "    # Mount Google Driveroo\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Add the path to the Python module\n",
    "    root_dir = '/content/drive/MyDrive/text_summarization'\n",
    "    sys.path.append(os.path.join(root_dir, 'src'))\n",
    "    sys.path.append(os.path.join(root_dir, 'src', 'utils'))\n",
    "else:\n",
    "    from pathlib import Path\n",
    "    root_dir = Path.cwd().parent\n",
    "root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c378699a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1932,
     "status": "ok",
     "timestamp": 1748290427445,
     "user": {
      "displayName": "IN FP",
      "userId": "08561517695641011702"
     },
     "user_tz": -120
    },
    "id": "c378699a",
    "outputId": "e626591d-073b-4109-bd8e-f7bdf8f08db0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/johannes/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95a219a2",
   "metadata": {
    "id": "95a219a2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johannes/opt/anaconda3/envs/Language_Engineering_pip/lib/python3.11/site-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n"
     ]
    }
   ],
   "source": [
    "from utils.preprocessing import preprocessing_pipeline, get_data_distribution\n",
    "from utils.processing import processing_pipeline, processing_pipeline_packed\n",
    "from utils.data_structures import create_packed_dataloader\n",
    "from train_model import main, tuning\n",
    "import utils.inference as inference\n",
    "from optuna.visualization import (plot_optimization_history,\n",
    "                                  plot_param_importances, plot_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66186581",
   "metadata": {
    "id": "66186581"
   },
   "outputs": [],
   "source": [
    "PROCESSING = True\n",
    "PREPROCESSING = True\n",
    "HYP_TUNING = True\n",
    "legacy = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b8b3c11",
   "metadata": {
    "id": "3b8b3c11"
   },
   "outputs": [],
   "source": [
    "name = \"WikiHow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dddaa8e0",
   "metadata": {
    "id": "dddaa8e0"
   },
   "outputs": [],
   "source": [
    "raw_dir = os.path.join(root_dir, \"raw_data\", name)\n",
    "if legacy:\n",
    "    dataset_dir = os.path.join(root_dir, \"data\", name)\n",
    "    figures_dir = os.path.join(root_dir, \"figures\", name)\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "    os.makedirs(figures_dir, exist_ok=True)\n",
    "else:\n",
    "    dataset_dir = os.path.join(root_dir, \"data_packed\", name)\n",
    "    figures_dir = os.path.join(root_dir, \"figures_packed\", name)\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "    os.makedirs(figures_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1ffb00",
   "metadata": {
    "id": "4d1ffb00"
   },
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3a38208",
   "metadata": {
    "id": "c3a38208"
   },
   "outputs": [],
   "source": [
    "dataset_df = pd.read_csv(os.path.join(raw_dir, \"wikihowSep.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db627eaf",
   "metadata": {
    "id": "db627eaf"
   },
   "outputs": [],
   "source": [
    "csv_name = \"wikihow_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31e12c1",
   "metadata": {
    "id": "e31e12c1"
   },
   "source": [
    "## Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "549c6283",
   "metadata": {
    "id": "549c6283"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johannes/Studium/Master/6. Semester/Language engineering/Project/text_summarization/src/utils/preprocessing.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = start_token + df[column_name] + end_token\n",
      "/Users/johannes/Studium/Master/6. Semester/Language engineering/Project/text_summarization/src/utils/preprocessing.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'length_{column_name}'] = df[column_name].apply(lambda x: len(x.split()))\n",
      "/Users/johannes/Studium/Master/6. Semester/Language engineering/Project/text_summarization/src/utils/preprocessing.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name] = start_token + df[column_name] + end_token\n",
      "/Users/johannes/Studium/Master/6. Semester/Language engineering/Project/text_summarization/src/utils/preprocessing.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'length_{column_name}'] = df[column_name].apply(lambda x: len(x.split()))\n"
     ]
    }
   ],
   "source": [
    "if PREPROCESSING:\n",
    "    subset_size = 0.2 # Change later back to 50%\n",
    "    preprocessing_pipeline(dataset_df, stopwords, dataset_dir, csv_name, subset_size = subset_size, start_token = \"SOS \", end_token = \" EOS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31f09257",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5335,
     "status": "ok",
     "timestamp": 1748290468515,
     "user": {
      "displayName": "IN FP",
      "userId": "08561517695641011702"
     },
     "user_tz": -120
    },
    "id": "31f09257",
    "outputId": "eda4d71c-8c70-4912-9e2f-24a19e659e43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 269126 entries, 0 to 269125\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   summary         269126 non-null  object\n",
      " 1   text            269126 non-null  object\n",
      " 2   length_summary  269126 non-null  int64 \n",
      " 3   length_text     269126 non-null  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 8.2+ MB\n"
     ]
    }
   ],
   "source": [
    "if legacy:\n",
    "    dataset_df = pd.read_csv(os.path.join(root_dir, \"data\", name, f'{csv_name}.csv'))\n",
    "else:\n",
    "    dataset_df = pd.read_csv(os.path.join(root_dir, \"data_packed\", name, f'{csv_name}.csv'))\n",
    "    \n",
    "dataset_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "kSWsLCeWKqcg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1748290468527,
     "user": {
      "displayName": "IN FP",
      "userId": "08561517695641011702"
     },
     "user_tz": -120
    },
    "id": "kSWsLCeWKqcg",
    "outputId": "c2daf0b4-dd08-4f23-b148-f3109c9e9c67"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "      <th>length_summary</th>\n",
       "      <th>length_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SOS put yourself out there EOS</td>\n",
       "      <td>SOS its simpleif you dont put yourself into ne...</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SOS hold your finger down to open closing opti...</td>\n",
       "      <td>SOS on some devices running dolphin you can al...</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOS combine beeswax and turpentine to create a...</td>\n",
       "      <td>SOS mix 1 part beeswax with 3 parts turpentine...</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SOS let up on the clutch while pushing down on...</td>\n",
       "      <td>SOS in order to get moving lift your left foot...</td>\n",
       "      <td>13</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SOS locate the song you would like to rate EOS</td>\n",
       "      <td>SOS using the scroll wheel locate the song tha...</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             summary  \\\n",
       "0                     SOS put yourself out there EOS   \n",
       "1  SOS hold your finger down to open closing opti...   \n",
       "2  SOS combine beeswax and turpentine to create a...   \n",
       "3  SOS let up on the clutch while pushing down on...   \n",
       "4     SOS locate the song you would like to rate EOS   \n",
       "\n",
       "                                                text  length_summary  \\\n",
       "0  SOS its simpleif you dont put yourself into ne...               6   \n",
       "1  SOS on some devices running dolphin you can al...              10   \n",
       "2  SOS mix 1 part beeswax with 3 parts turpentine...              10   \n",
       "3  SOS in order to get moving lift your left foot...              13   \n",
       "4  SOS using the scroll wheel locate the song tha...              10   \n",
       "\n",
       "   length_text  \n",
       "0           40  \n",
       "1           31  \n",
       "2           22  \n",
       "3          172  \n",
       "4           15  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15abfd00",
   "metadata": {
    "id": "15abfd00"
   },
   "source": [
    "## Get distribution of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8f0f01",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 602
    },
    "executionInfo": {
     "elapsed": 8582,
     "status": "ok",
     "timestamp": 1748290477113,
     "user": {
      "displayName": "IN FP",
      "userId": "08561517695641011702"
     },
     "user_tz": -120
    },
    "id": "cb8f0f01",
    "outputId": "476bc6e5-ac3f-46e8-920b-f1eab97b9466"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johannes/Studium/Master/6. Semester/Language engineering/Project/text_summarization/src/utils/preprocessing.py:99: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "get_data_distribution(dataset_df, figures_dir, \"wikihow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596a84bd",
   "metadata": {
    "id": "596a84bd"
   },
   "source": [
    "## Process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a564bcf3",
   "metadata": {
    "id": "a564bcf3"
   },
   "outputs": [],
   "source": [
    "load_tokenizer = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6d4ef07-990c-4b19-906b-ca0c75c4e833",
   "metadata": {
    "id": "90a837db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of text: 243\n",
      "Max length of summary: 30\n",
      "SOS token index: 1\n",
      "EOS token index: 2\n",
      "UNK token index: 3\n",
      "PAD token index: 0\n",
      "Number of Samples in X_train: 188388\n",
      "Number of Samples in X_val: 48442\n",
      "Number of Samples in X_test: 32296\n",
      "Number of Samples in y_train: 188388\n",
      "Number of Samples in y_val: 48442\n",
      "Number of Samples in y_test: 32296\n",
      "Vocabulary size: 283401\n",
      "Saving x_train_list.pt...\n",
      "x_train_list.pt dtype: torch.int64, shape: torch.Size([74])\n",
      "Saving x_val_list.pt...\n",
      "x_val_list.pt dtype: torch.int64, shape: torch.Size([173])\n",
      "Saving x_test_list.pt...\n",
      "x_test_list.pt dtype: torch.int64, shape: torch.Size([18])\n",
      "Saving y_train_list.pt...\n",
      "y_train_list.pt dtype: torch.int64, shape: torch.Size([7])\n",
      "Saving y_val_list.pt...\n",
      "y_val_list.pt dtype: torch.int64, shape: torch.Size([5])\n",
      "Saving y_test_list.pt...\n",
      "y_test_list.pt dtype: torch.int64, shape: torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "if PROCESSING and legacy:\n",
    "    print('legacy used')\n",
    "    processing_pipeline(dataset_dir, csv_name, load_tokenizer = load_tokenizer)\n",
    "elif PROCESSING and not legacy:\n",
    "    processing_pipeline_packed(dataset_dir, csv_name, load_tokenizer=load_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4024c6ff-96de-466d-83e1-f7b14d280c67",
   "metadata": {},
   "source": [
    "### Test the processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33f75936-b37b-4668-8f04-5869ec579b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_decoding = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fc2362a-b656-413e-b6a7-663d3bc9311c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bq/ht4rq0pn2yqbdhn46m4mt1d00000gn/T/ipykernel_21749/3550391496.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  X_train = torch.load(os.path.join(dataset_dir, \"x_train_list.pt\"))\n",
      "/var/folders/bq/ht4rq0pn2yqbdhn46m4mt1d00000gn/T/ipykernel_21749/3550391496.py:35: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  y_train = torch.load(os.path.join(dataset_dir, \"y_train_list.pt\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: SOS attempting 24 multiple choice questions in 45 minutes is easy so instead of wasting time worrying read the questions carefully this will help you to score better you may even pass with flying colours EOS\n",
      "Target: SOS manage your time EOS\n",
      "-----------------------------------\n",
      "Input: SOS when the popcorn finishes cooking you should have a good amount of popcorn gathered at the bottom of the case use a large spoon or scoop most popcorn makers should have one included to serve the popcorn traditionally theater popcorn is served in paper bags but if you dont have any you can use ordinary bowls most popcorn machines have a number of holes in the bottom of the case for allowing unpopped kernels and very small crumbs to fall into a crumb drawer located below the bottom before serving the popcorn it is advisable to carefully rake the scoop back and forth so that those old maids will fall into the drawer EOS\n",
      "Target: SOS serve by scooping into bags EOS\n",
      "-----------------------------------\n",
      "Input: SOS cheerio mix is a fun simple mix that rabbits and other small animals will enjoy you will need a handful of cheerios a handful of sunflower seeds some rabbit pellets and a handful of dry oats mix the ingredients together and serve to your rabbitthese are best given as an occasional treat the sugar in cheerios could cause health problems if given regularly EOS\n",
      "Target: SOS try a cheerio mix EOS\n",
      "-----------------------------------\n",
      "Input: SOS make the leaves by putting 1 leaf block on top of the fences stack them up more until they are the height you want them to be make a horizontal line from the bottom leaf that is the same length as the amount of blocks you put on top EOS\n",
      "Target: SOS add the leaves EOS\n",
      "-----------------------------------\n",
      "Input: SOS posts that include at least one hashtag will typically gain 126 more engagement try to understand your audience and write down hashtags that are included in the most popular posts that you see youll want to add more targeted hashtags so that people looking for something specific can find your content youll also want to post more general hashtags to increase the number of likes and exposure you getpopular hashtags include fashiongoals instafashion instagood photooftheday as well as more general hashtags like love happy and dog EOS\n",
      "Target: SOS use hashtags EOS\n",
      "-----------------------------------\n",
      "Input: SOS an entire agreement clause also known as an integration clause states that this document is the complete agreement of the parties and supersedes any prior oral or written agreementsthis prevents a party from claiming later that some there was an agreement on some term not included in the contract that should be made part of the contract for example this agreement constitutes the entire agreement of the parties and supersedes all prior or contemporaneous oral or written agreements concerning the subject matter EOS\n",
      "Target: SOS consider an entire agreement clause EOS\n",
      "-----------------------------------\n",
      "Input: SOS in order to get on your merry certified way youll need to submit your credential review application and college transcripts to the cncb then you should obtain credential approval from the board and begin your pgscn course eventually taking the ccn exam EOS\n",
      "Target: SOS get through all the paperwork EOS\n",
      "-----------------------------------\n",
      "Input: SOS your landlord might tack on late charges or interest to any late paymentoften these charges and fees are spelled out in your lease take out the lease and read it you should ask if you can get the late fees waived your landlord might not agree but it is worth asking you dont want to pay more than you have to EOS\n",
      "Target: SOS try to get late fees waived EOS\n",
      "-----------------------------------\n",
      "Input: SOS cover the chairs and sofas in your reception area with vintage throw pillows throw pillows give the feel of an oldfashioned parlor room and can be a great means to give your wedding decor a vintage styleyou can stop by a local antique shop to find vintage throw pillows you can also talk to older friends and relatives to see if they have any throw pillows theyd be willing to donate keep your color scheme in mind when selecting throw pillows choose pillows that match your wedding colors EOS\n",
      "Target: SOS go for vintage throw pillows EOS\n",
      "-----------------------------------\n",
      "Input: SOS your subject will be the star of the story whether it be a person or an animal keep in mind that most readers do not like mary sues or characters who come across as perfect in every way make your characters have flaws but make sure they have talents too EOS\n",
      "Target: SOS find a subject EOS\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "if test_decoding:\n",
    "    import torch\n",
    "    import pickle\n",
    "    import random\n",
    "    \n",
    "    def decode_data(text_ids, index2word, EOS_token):\n",
    "        \"\"\"\n",
    "        Converts the text ids to words using the index2word mapping.\n",
    "        \"\"\"\n",
    "        if text_ids.dim() > 1:\n",
    "            text_ids = text_ids.view(-1)  # Flatten to 1D\n",
    "    \n",
    "        decoded_words = []\n",
    "        for idx in text_ids:\n",
    "            # Ensure idx is a scalar\n",
    "            if isinstance(idx, torch.Tensor):\n",
    "                idx = idx.item()\n",
    "            if idx == EOS_token:\n",
    "                decoded_words.append('EOS')\n",
    "                break\n",
    "            decoded_words.append(index2word.get(idx, 'UNK'))\n",
    "    \n",
    "        return \" \".join(decoded_words)\n",
    "    \n",
    "    if legacy:\n",
    "        X_train = torch.load(os.path.join(dataset_dir, \"x_train.pt\"))\n",
    "        y_train = torch.load(os.path.join(dataset_dir, \"y_train.pt\"))\n",
    "        train_dataloader = torch.utils.data.DataLoader(\n",
    "            torch.utils.data.TensorDataset(X_train, y_train),\n",
    "            batch_size=1,\n",
    "            shuffle=False,\n",
    "            )\n",
    "    else:\n",
    "        X_train = torch.load(os.path.join(dataset_dir, \"x_train_list.pt\"))\n",
    "        y_train = torch.load(os.path.join(dataset_dir, \"y_train_list.pt\"))\n",
    "        train_dataloader = create_packed_dataloader(X_train, y_train, pad_id=0, batch_size=1, shuffle=False)\n",
    "    \n",
    "    \n",
    "    with open(os.path.join(dataset_dir, 'feature_tokenizer.pickle'), 'rb') as handle:\n",
    "            feature_tokenizer = pickle.load(handle)\n",
    "    EOS_token = feature_tokenizer.word2index.get(\"EOS\", 2)\n",
    "    \n",
    "    nb_decoding_test = 10\n",
    "    count_test = 0\n",
    "    random_list = random.sample(range(len(train_dataloader)), nb_decoding_test)\n",
    "    if legacy:\n",
    "        for i, data in enumerate(train_dataloader):\n",
    "            if i in random_list:\n",
    "                input_tensor, target_tensor = data\n",
    "                print('Input: {}'.format(decode_data(input_tensor[0], feature_tokenizer.index2word, EOS_token)))\n",
    "                print('Target: {}'.format(decode_data(target_tensor[0], feature_tokenizer.index2word, EOS_token)))\n",
    "                print('-----------------------------------')\n",
    "                count_test += 1\n",
    "            if count_test == nb_decoding_test:\n",
    "                break\n",
    "    else:\n",
    "        for i, data in enumerate(train_dataloader):\n",
    "            if i in random_list:\n",
    "                input_tensor, input_lengths, target_tensor, target_lengths = data\n",
    "                print('Input: {}'.format(decode_data(input_tensor[0], feature_tokenizer.index2word, EOS_token)))\n",
    "                print('Target: {}'.format(decode_data(target_tensor[0], feature_tokenizer.index2word, EOS_token)))\n",
    "                print('-----------------------------------')\n",
    "                count_test += 1\n",
    "            if count_test == nb_decoding_test:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b32c9d",
   "metadata": {
    "id": "17b32c9d"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7f42f2",
   "metadata": {
    "id": "db7f42f2"
   },
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "max_length = 100\n",
    "lr = 0.001\n",
    "weight_decay = 1e-6\n",
    "batch_size = 128\n",
    "num_workers = 2\n",
    "n_epochs = 100\n",
    "print_example_every = 10\n",
    "load_checkpoint = False\n",
    "early_stopping_patience = 5\n",
    "log_every = 2000\n",
    "\n",
    "optimizer_hyperparams = {\n",
    "    'learning_rate': lr,\n",
    "    'weight_decay': weight_decay,\n",
    "    'n_epochs': n_epochs,\n",
    "    'batch_size': batch_size,\n",
    "    'num_workers': num_workers,\n",
    "    'early_stopping_patience': early_stopping_patience\n",
    "}\n",
    "\n",
    "model_hyperparams = {\n",
    "    'hidden_size': hidden_size,\n",
    "    'max_length': max_length\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bde23ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "executionInfo": {
     "elapsed": 977047,
     "status": "error",
     "timestamp": 1748294670175,
     "user": {
      "displayName": "IN FP",
      "userId": "08561517695641011702"
     },
     "user_tz": -120
    },
    "id": "7bde23ac",
    "outputId": "b5ef08c6-afff-40e7-a72c-49936dcaf55f"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "main() missing 1 required positional argument: 'log_every'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_hyperparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_hyperparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtuning\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtuning\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer_hyperparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer_hyperparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_examples_every\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_example_every\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mload_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlegacy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlegacy\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: main() missing 1 required positional argument: 'log_every'"
     ]
    }
   ],
   "source": [
    "main(root_dir = root_dir,\n",
    "    model_hyperparams=model_hyperparams,\n",
    "    tuning = tuning, \n",
    "    optimizer_hyperparams=optimizer_hyperparams,\n",
    "    log_every = log_every,\n",
    "    print_examples_every=print_example_every,\n",
    "    load_checkpoint=load_checkpoint,\n",
    "    name=name,\n",
    "    legacy=legacy\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0617b5c-6156-4ee1-a78a-cb59fbc2f243",
   "metadata": {},
   "source": [
    "### Making inference with the model (on a CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025c633a-f75d-4142-bae2-933a08c54671",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = 'best_checkpoint.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d585a80d-a92f-435a-b6e3-015eea7b9f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    input_tensor = input(\"Enter the text to summarize (or type 'exit' to quit): \")\n",
    "    if input_tensor.lower() == 'exit':\n",
    "        break\n",
    "    # Don't forget to water your plants, they need it to survive.\n",
    "    inference.main(root_dir, name, checkpoint_name, hidden_size, max_length, input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c090fe-4407-4a3c-b6f2-f47d6836f31a",
   "metadata": {},
   "source": [
    "### Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09efad8-2f38-4175-9b97-069ce8f46420",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c77807-8a8a-4171-b806-cd5a9ea9f052",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HYP_TUNING:\n",
    "    study = tuning(root_dir, num_trials, name)\n",
    "    # Save the study results\n",
    "    study_dir = os.path.join(root_dir, 'parameters_tuning', name, 'study_results')\n",
    "    os.makedirs(study_dir, exist_ok=True)\n",
    "    \n",
    "    # Save the optimization history\n",
    "    plot_optimization_history(study)\n",
    "    \n",
    "    # Save the parameter importances\n",
    "    plot_param_importances(study)\n",
    "    \n",
    "    # Save the slice plot\n",
    "    plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496f806a-4f1a-4702-81f3-1ad73a08bfd4",
   "metadata": {},
   "source": [
    "### Check training information with tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d951d2-ca13-47a6-b99b-27730cefe1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# !tensorboard --logdir='tensorboard_logs'"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Language_Engineering_pip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
